{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karanbhatt230803/Detection-of-Rogue-Drones-on-Border/blob/main/Detection_of_Drones_on_Border.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrsaDfdVHzxt"
      },
      "source": [
        "# Custom Training with YOLOv5\n",
        "\n",
        "In this tutorial, we assemble a dataset and train a custom YOLOv5 model to recognize the objects in our dataset. To do so we will take the following steps:\n",
        "\n",
        "* Gather a dataset of images and label our dataset\n",
        "* Export our dataset to YOLOv5\n",
        "* Train YOLOv5 to recognize the objects in our dataset\n",
        "* Evaluate our YOLOv5 model's performance\n",
        "* Run test inference to view our model at work\n",
        "\n",
        "\n",
        "\n",
        "![](https://uploads-ssl.webflow.com/5f6bc60e665f54545a1e52a5/615627e5824c9c6195abfda9_computer-vision-cycle.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNveqeA1KXGy"
      },
      "source": [
        "# Step 1: Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTvDNSILZoN9",
        "outputId": "82a3552d-b941-4920-e9c9-1a466f6e7585"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 13609, done.\u001b[K\n",
            "remote: Counting objects: 100% (411/411), done.\u001b[K\n",
            "remote: Compressing objects: 100% (125/125), done.\u001b[K\n",
            "remote: Total 13609 (delta 299), reused 388 (delta 286), pack-reused 13198\u001b[K\n",
            "Receiving objects: 100% (13609/13609), 13.21 MiB | 8.34 MiB/s, done.\n",
            "Resolving deltas: 100% (9360/9360), done.\n",
            "/content/yolov5\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.6 MB 47.0 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 145 kB 39.6 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 178 kB 69.6 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1 MB 57.3 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67 kB 6.4 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54 kB 3.5 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 138 kB 68.9 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62 kB 1.5 MB/s \n",
            "\u001b[?25h  Building wheel for roboflow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Setup complete. Using torch 1.12.1+cu113 (Tesla T4)\n"
          ]
        }
      ],
      "source": [
        "#clone YOLOv5 and \n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt # install dependencies\n",
        "%pip install -q roboflow\n",
        "\n",
        "import torch\n",
        "import os\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlNtn68n9LV3"
      },
      "outputs": [],
      "source": [
        "!unzip -q ../train_dataset.zip -d ../\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP6USLgz2f0r"
      },
      "source": [
        "# Step 2: Assemble Our Dataset\n",
        "\n",
        "In order to train our custom model, we need to assemble a dataset of representative images with bounding box annotations around the objects that we want to detect. And we need our dataset to be in YOLOv5 format.\n",
        "\n",
        "In Roboflow, you can choose between two paths:\n",
        "\n",
        "* Convert an existing dataset to YOLOv5 format. Roboflow supports over [30 formats object detection formats](https://roboflow.com/formats) for conversion.\n",
        "* Upload raw images and annotate them in Roboflow with [Roboflow Annotate](https://docs.roboflow.com/annotate).\n",
        "\n",
        "# Annotate\n",
        "\n",
        "![](https://roboflow-darknet.s3.us-east-2.amazonaws.com/roboflow-annotate.gif)\n",
        "\n",
        "# Version\n",
        "\n",
        "![](https://roboflow-darknet.s3.us-east-2.amazonaws.com/robolfow-preprocessing.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2wGvjd4Z_92",
        "outputId": "9b100d09-654e-4c01-e77d-71d3ec4264c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "upload and label your dataset, and get an API KEY here: https://app.roboflow.com/?model=yolov5&ref=ultralytics\n"
          ]
        }
      ],
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(model_format=\"yolov5\", notebook=\"ultralytics\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jjT5uIHo6l5"
      },
      "outputs": [],
      "source": [
        "# set up environment\n",
        "os.environ[\"DATASET_DIRECTORY\"] = \"/content/datasets\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwJcaoPGF4VI",
        "outputId": "4e22e5ac-6980-403e-a723-ba205596761c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in /content/datasets/American-Mushrooms-1 to yolov5pytorch: 100% [3866359 / 3866359] bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting Dataset Version Zip to /content/datasets/American-Mushrooms-1 in yolov5pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 278/278 [00:00<00:00, 1046.33it/s]\n"
          ]
        }
      ],
      "source": [
        "#after following the link above, recieve python code with these fields filled in\n",
        "#from roboflow import Roboflow\n",
        "#rf = Roboflow(api_key=\"YOUR API KEY HERE\")\n",
        "#project = rf.workspace().project(\"YOUR PROJECT\")\n",
        "#dataset = project.version(\"YOUR VERSION\").download(\"yolov5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7yAi9hd-T4B"
      },
      "source": [
        "# Step 3: Train Our Custom YOLOv5 model\n",
        "\n",
        "Here, we are able to pass a number of arguments:\n",
        "- **img:** define input image size\n",
        "- **batch:** determine batch size\n",
        "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
        "- **data:** Our dataset locaiton is saved in the `dataset.location`\n",
        "- **weights:** specify a path to weights to start transfer learning from. Here we choose the generic COCO pretrained checkpoint.\n",
        "- **cache:** cache images for faster training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaFNnxLJbq4J",
        "outputId": "2ecaa84c-6d89-4829-dc09-90bf787d23b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=custom_dataset.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=60, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v6.2-187-g5ef69ef Python-3.7.14 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs in Weights & Biases\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 ðŸš€ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ðŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/train_dataset/labels/train.cache' images and labels... 147 found, 0 missing, 0 empty, 0 corrupt: 100% 147/147 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram): 100% 147/147 [00:03<00:00, 46.88it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/train_dataset/labels/val.cache' images and labels... 68 found, 0 missing, 0 empty, 0 corrupt: 100% 68/68 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 68/68 [00:01<00:00, 35.35it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.15 anchors/target, 0.994 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Plotting labels to runs/train/exp2/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp2\u001b[0m\n",
            "Starting training for 60 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/59      1.75G     0.1186    0.01986          0          8        416: 100% 10/10 [00:04<00:00,  2.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  3.93it/s]\n",
            "                   all         68         78     0.0147      0.603     0.0305    0.00835\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/59      2.12G     0.1052    0.02379          0          9        416: 100% 10/10 [00:01<00:00,  5.87it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  4.51it/s]\n",
            "                   all         68         78     0.0558      0.179     0.0328    0.00762\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/59      2.12G    0.09254    0.02428          0          5        416: 100% 10/10 [00:01<00:00,  6.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  5.07it/s]\n",
            "                   all         68         78      0.146      0.269      0.115     0.0341\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/59      2.12G    0.08197    0.02581          0          8        416: 100% 10/10 [00:01<00:00,  6.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  5.54it/s]\n",
            "                   all         68         78      0.406       0.41      0.382       0.13\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/59      2.12G    0.07134    0.02625          0         12        416: 100% 10/10 [00:01<00:00,  6.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  5.94it/s]\n",
            "                   all         68         78       0.47      0.564      0.505      0.204\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/59      2.12G    0.06811    0.02238          0          6        416: 100% 10/10 [00:01<00:00,  6.36it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.19it/s]\n",
            "                   all         68         78      0.558      0.603      0.649      0.261\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/59      2.12G      0.067     0.0229          0         11        416: 100% 10/10 [00:01<00:00,  6.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  5.89it/s]\n",
            "                   all         68         78      0.715      0.641      0.718      0.331\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/59      2.12G    0.06308    0.02178          0         10        416: 100% 10/10 [00:01<00:00,  6.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.07it/s]\n",
            "                   all         68         78      0.654      0.615      0.652      0.224\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/59      2.12G    0.06169    0.01997          0          5        416: 100% 10/10 [00:01<00:00,  6.53it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.67it/s]\n",
            "                   all         68         78      0.736      0.564      0.702       0.35\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/59      2.12G     0.0654    0.02023          0          8        416: 100% 10/10 [00:01<00:00,  6.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.52it/s]\n",
            "                   all         68         78      0.793      0.639      0.731      0.334\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/59      2.12G    0.05842    0.02248          0         13        416: 100% 10/10 [00:01<00:00,  6.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.64it/s]\n",
            "                   all         68         78      0.742      0.663       0.77      0.382\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/59      2.12G    0.05767    0.01937          0          7        416: 100% 10/10 [00:01<00:00,  6.24it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.45it/s]\n",
            "                   all         68         78      0.738      0.641      0.747      0.401\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/59      2.12G    0.05453     0.0209          0         14        416: 100% 10/10 [00:01<00:00,  6.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.43it/s]\n",
            "                   all         68         78      0.669      0.673      0.719      0.381\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/59      2.12G    0.05214     0.0192          0          8        416: 100% 10/10 [00:01<00:00,  6.12it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.89it/s]\n",
            "                   all         68         78      0.754      0.745      0.842      0.343\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/59      2.12G     0.0482    0.01823          0          6        416: 100% 10/10 [00:01<00:00,  6.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.37it/s]\n",
            "                   all         68         78      0.813      0.795      0.874      0.442\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/59      2.12G    0.04663    0.01659          0          6        416: 100% 10/10 [00:01<00:00,  6.13it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  7.05it/s]\n",
            "                   all         68         78       0.68      0.808       0.77       0.37\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/59      2.12G    0.04566    0.01872          0         12        416: 100% 10/10 [00:01<00:00,  6.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.81it/s]\n",
            "                   all         68         78      0.876      0.846      0.889      0.503\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/59      2.12G    0.04449    0.01795          0          6        416: 100% 10/10 [00:01<00:00,  6.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.93it/s]\n",
            "                   all         68         78       0.62      0.733      0.758      0.415\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/59      2.12G    0.04607    0.01685          0         11        416: 100% 10/10 [00:01<00:00,  6.57it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.37it/s]\n",
            "                   all         68         78      0.536       0.91      0.705      0.401\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/59      2.12G    0.04108    0.01612          0          5        416: 100% 10/10 [00:01<00:00,  6.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.51it/s]\n",
            "                   all         68         78      0.882      0.897       0.95      0.565\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/59      2.12G    0.03988    0.01601          0          6        416: 100% 10/10 [00:01<00:00,  6.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.43it/s]\n",
            "                   all         68         78      0.845      0.897      0.935      0.578\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/59      2.12G    0.04164    0.01616          0          8        416: 100% 10/10 [00:01<00:00,  6.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.71it/s]\n",
            "                   all         68         78      0.849      0.935      0.878      0.529\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/59      2.12G    0.03734    0.01737          0          9        416: 100% 10/10 [00:01<00:00,  6.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.31it/s]\n",
            "                   all         68         78      0.967       0.91      0.957       0.55\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/59      2.12G    0.03803    0.01531          0          6        416: 100% 10/10 [00:01<00:00,  6.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.51it/s]\n",
            "                   all         68         78      0.972      0.906       0.96      0.608\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/59      2.12G    0.03733    0.01595          0          8        416: 100% 10/10 [00:01<00:00,  6.12it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.34it/s]\n",
            "                   all         68         78      0.972      0.896      0.958      0.581\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/59      2.12G    0.03728    0.01581          0         10        416: 100% 10/10 [00:01<00:00,  6.10it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.57it/s]\n",
            "                   all         68         78      0.959      0.904      0.954      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/59      2.12G    0.03521     0.0148          0         10        416: 100% 10/10 [00:01<00:00,  6.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.38it/s]\n",
            "                   all         68         78       0.97      0.923      0.958      0.654\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/59      2.12G     0.0369    0.01506          0         11        416: 100% 10/10 [00:01<00:00,  6.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.99it/s]\n",
            "                   all         68         78      0.986       0.92       0.95       0.54\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/59      2.12G    0.03412    0.01371          0          6        416: 100% 10/10 [00:01<00:00,  6.37it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.83it/s]\n",
            "                   all         68         78      0.982       0.91      0.949      0.575\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/59      2.12G    0.03374    0.01404          0          6        416: 100% 10/10 [00:01<00:00,  6.06it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.62it/s]\n",
            "                   all         68         78      0.978      0.897      0.949      0.644\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/59      2.12G    0.03295    0.01459          0          5        416: 100% 10/10 [00:01<00:00,  6.23it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.50it/s]\n",
            "                   all         68         78      0.983       0.91      0.949      0.637\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/59      2.12G    0.03269    0.01354          0          7        416: 100% 10/10 [00:01<00:00,  6.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.65it/s]\n",
            "                   all         68         78      0.983       0.91      0.936      0.597\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/59      2.12G    0.03172    0.01286          0          6        416: 100% 10/10 [00:01<00:00,  6.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.73it/s]\n",
            "                   all         68         78      0.983       0.91      0.943      0.618\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/59      2.12G    0.03141    0.01238          0          6        416: 100% 10/10 [00:01<00:00,  6.39it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.77it/s]\n",
            "                   all         68         78      0.983       0.91      0.933      0.597\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/59      2.12G    0.03073    0.01364          0          6        416: 100% 10/10 [00:01<00:00,  6.72it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.48it/s]\n",
            "                   all         68         78      0.969      0.923      0.933      0.561\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/59      2.12G    0.02848      0.013          0          6        416: 100% 10/10 [00:01<00:00,  6.53it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.66it/s]\n",
            "                   all         68         78      0.972      0.936      0.934      0.639\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/59      2.12G    0.03107    0.01392          0          8        416: 100% 10/10 [00:01<00:00,  6.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.70it/s]\n",
            "                   all         68         78      0.973      0.934      0.944      0.639\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/59      2.12G    0.02993    0.01297          0          7        416: 100% 10/10 [00:01<00:00,  6.37it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.76it/s]\n",
            "                   all         68         78      0.972      0.936      0.955      0.637\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/59      2.12G     0.0291    0.01363          0         13        416: 100% 10/10 [00:01<00:00,  6.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.32it/s]\n",
            "                   all         68         78      0.973      0.936      0.964      0.636\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/59      2.12G    0.02932     0.0135          0         11        416: 100% 10/10 [00:01<00:00,  6.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.75it/s]\n",
            "                   all         68         78       0.96      0.936       0.97      0.635\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/59      2.12G    0.02677    0.01258          0          5        416: 100% 10/10 [00:01<00:00,  6.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.26it/s]\n",
            "                   all         68         78      0.958      0.936       0.97      0.642\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/59      2.12G    0.02789    0.01417          0         12        416: 100% 10/10 [00:01<00:00,  6.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.86it/s]\n",
            "                   all         68         78       0.96      0.933      0.973      0.638\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/59      2.12G    0.02731     0.0142          0          4        416: 100% 10/10 [00:01<00:00,  6.33it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.12it/s]\n",
            "                   all         68         78      0.969      0.923      0.975      0.628\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/59      2.12G    0.02736    0.01228          0          8        416: 100% 10/10 [00:01<00:00,  6.12it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.63it/s]\n",
            "                   all         68         78      0.971      0.923      0.969      0.629\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/59      2.12G    0.02778    0.01308          0         11        416: 100% 10/10 [00:01<00:00,  6.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.70it/s]\n",
            "                   all         68         78       0.97      0.923      0.963      0.639\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/59      2.12G    0.02533    0.01298          0         12        416: 100% 10/10 [00:01<00:00,  6.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.78it/s]\n",
            "                   all         68         78      0.948      0.936      0.959      0.643\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/59      2.12G    0.02547    0.01286          0         10        416: 100% 10/10 [00:01<00:00,  6.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.49it/s]\n",
            "                   all         68         78      0.973      0.921       0.96      0.647\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/59      2.12G     0.0236    0.01329          0         13        416: 100% 10/10 [00:01<00:00,  6.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.97it/s]\n",
            "                   all         68         78      0.967      0.923      0.954      0.673\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/59      2.12G    0.02435    0.01249          0          8        416: 100% 10/10 [00:01<00:00,  6.36it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.68it/s]\n",
            "                   all         68         78      0.969      0.923      0.951      0.662\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/59      2.12G     0.0243     0.0108          0          7        416: 100% 10/10 [00:01<00:00,  6.28it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.85it/s]\n",
            "                   all         68         78      0.958      0.923      0.944      0.663\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      50/59      2.12G    0.02385    0.01199          0          6        416: 100% 10/10 [00:01<00:00,  6.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.62it/s]\n",
            "                   all         68         78      0.958      0.923      0.946       0.67\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      51/59      2.12G    0.02298    0.01087          0          7        416: 100% 10/10 [00:01<00:00,  6.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.86it/s]\n",
            "                   all         68         78      0.973      0.921      0.943      0.675\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      52/59      2.12G    0.02333    0.01171          0         10        416: 100% 10/10 [00:01<00:00,  6.57it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.93it/s]\n",
            "                   all         68         78      0.972      0.923      0.944      0.677\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      53/59      2.12G    0.02412    0.01101          0          7        416: 100% 10/10 [00:01<00:00,  6.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.88it/s]\n",
            "                   all         68         78      0.973      0.923      0.943      0.678\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      54/59      2.12G    0.02424    0.01177          0          6        416: 100% 10/10 [00:02<00:00,  4.34it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  4.63it/s]\n",
            "                   all         68         78      0.973      0.922      0.947      0.672\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      55/59      2.12G    0.02242     0.0121          0          7        416: 100% 10/10 [00:01<00:00,  5.89it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  7.03it/s]\n",
            "                   all         68         78       0.96      0.933      0.946      0.677\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      56/59      2.12G    0.02312    0.01175          0          9        416: 100% 10/10 [00:01<00:00,  6.65it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.46it/s]\n",
            "                   all         68         78      0.958      0.936      0.947      0.682\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      57/59      2.12G    0.02519    0.01231          0          8        416: 100% 10/10 [00:01<00:00,  6.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.70it/s]\n",
            "                   all         68         78      0.983      0.923       0.95      0.679\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      58/59      2.12G    0.02343    0.01074          0          5        416: 100% 10/10 [00:01<00:00,  6.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.38it/s]\n",
            "                   all         68         78      0.984      0.923      0.952       0.68\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      59/59      2.12G    0.02355    0.01273          0         10        416: 100% 10/10 [00:01<00:00,  6.28it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  6.82it/s]\n",
            "                   all         68         78      0.986       0.93      0.951      0.691\n",
            "\n",
            "60 epochs completed in 0.042 hours.\n",
            "Optimizer stripped from runs/train/exp2/weights/last.pt, 14.3MB\n",
            "Optimizer stripped from runs/train/exp2/weights/best.pt, 14.3MB\n",
            "\n",
            "Validating runs/train/exp2/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  3.18it/s]\n",
            "                   all         68         78      0.986       0.93      0.951      0.694\n",
            "Results saved to \u001b[1mruns/train/exp2\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python train.py --img 416 --batch 16 --epochs 60 --data custom_dataset.yaml --weights yolov5s.pt --cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcIRLQOlA14A"
      },
      "source": [
        "# Evaluate Custom YOLOv5 Detector Performance\n",
        "Training losses and performance metrics are saved to Tensorboard and also to a logfile.\n",
        "\n",
        "If you are new to these metrics, the one you want to focus on is `mAP_0.5` - learn more about mean average precision [here](https://blog.roboflow.com/mean-average-precision/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jS9_BxdBBHL"
      },
      "outputs": [],
      "source": [
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "# logs save in the folder \"runs\"\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtmS7_TXFsT3"
      },
      "source": [
        "#Run Inference  With Trained Weights\n",
        "Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWjjiBcic3Vz",
        "outputId": "fc66484e-02b7-4e81-af74-6703dfea7c6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp/weights/best.pt'], source=/content/datasets/American-Mushrooms-1/test/images, imgsz=[416, 416], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False\n",
            "YOLOv5 ðŸš€ v5.0-471-g2993c3f torch 1.9.0+cu102 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7056607 parameters, 0 gradients, 16.3 GFLOPs\n",
            "image 1/5 /content/datasets/American-Mushrooms-1/test/images/chanterelle_02_jpg.rf.a75f69cbc359b824bb7ab938aae0f78c.jpg: 416x416 4 chanterelles, Done. (0.006s)\n",
            "image 2/5 /content/datasets/American-Mushrooms-1/test/images/chanterelle_03_jpg.rf.846e06d86f791840504a794757a1d309.jpg: 416x416 2 chanterelles, Done. (0.006s)\n",
            "image 3/5 /content/datasets/American-Mushrooms-1/test/images/chanterelle_03_jpg.rf.aafbddbccf9d72f9feb68bb7152e8589.jpg: 416x416 2 chanterelles, Done. (0.006s)\n",
            "image 4/5 /content/datasets/American-Mushrooms-1/test/images/chanterelle_07_jpg.rf.f303003864f398f85bb7c2c4949a94fc.jpg: 416x416 2 chanterelles, Done. (0.006s)\n",
            "image 5/5 /content/datasets/American-Mushrooms-1/test/images/chicken01_jpg.rf.9719bbb59afaa5cf16865e8550f372fc.jpg: 416x416 1 CoW, Done. (0.006s)\n",
            "Speed: 0.3ms pre-process, 6.0ms inference, 0.8ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python detect.py --weights runs/train/exp/weights/best.pt --img 416 --conf 0.1 --source {dataset.location}/test/images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8dHcni6CJYt"
      },
      "source": [
        "# Conclusion and Next Steps\n",
        "\n",
        "Congratulations! You've trained a custom YOLOv5 model to recognize your custom objects.\n",
        "\n",
        "To improve you model's performance, we recommend first interating on your datasets coverage and quality. See this guide for [model performance improvement](https://github.com/ultralytics/yolov5/wiki/Tips-for-Best-Training-Results).\n",
        "\n",
        "To deploy your model to an application, see this guide on [exporting your model to deployment destinations](https://github.com/ultralytics/yolov5/issues/251).\n",
        "\n",
        "Once your model is in production, you will want to continually iterate and improve on your dataset and model via [active learning](https://blog.roboflow.com/what-is-active-learning/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "7iiObB2WCMh6",
        "outputId": "5c2c1e8a-a857-4284-d627-42f99724c9e8"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_bd6fc902-d327-4332-bf86-0f81058a7d7f\", \"best.pt\", 14358689)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#export your model's weights for future use\n",
        "from google.colab import files\n",
        "files.download('./runs/train/exp/weights/best.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNn-obvOGITm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
